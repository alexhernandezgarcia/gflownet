_target_: gflownet.buffer.base.BaseBuffer

replay_buffer: null
replay_capacity: 0

# Train and test data
# Both train and test are dictionaries with the following keys:
# - type: type of data. It can be one of the following:
#   - pkl: a pickled file. Requires path.
#   - csv: a CSV file. Requires path.
#   - all: all terminating states of the environment.
#   - grid: a grid of terminating states. Requires n.
#   - uniform: terminating states uniformly sampled. Requires n.
#   - random: terminating states sampled randomly from the intial GFN policy. Requires n.
# - path: path to a CSV of pickled file (for type={pkl, csv})
# - n: number of samples (for type={grid, uniform, random})
# - seed: seed for random sampling (for type={uniform, random})
train:
  type: null
  path: null
  n: null
  seed: null
test:
  type: null
  path: null
  n: null
  seed: null

# Whether to maintain a separate "main" buffer for storing all terminal states visited during the training 
use_main_buffer: False

# Whether new samples are compared to samples in the buffer before adding
check_diversity: False

# The accepted level of similarity of rewards to include samples from the
# replay buffer in the diversity check. Assuming check_diversity is True, given
# a sample x with reward R(x), the diversity check will only be performed
# against those samples in the replay buffer whose reward difference with
# respect to R(x) is smaller than diversity_check_reward_similarity times the
# difference between the maximum reward and the minimum reward in the replay
# buffer.
diversity_check_reward_similarity: 0.1

# Whether to show a progress bar while processing the data sets. False by default.
progress_process_dataset: False
