# @package _global_

defaults:
   - override /env: tree
   - override /gflownet: trajectorybalance
   - override /policy: mlp
   - override /proxy: tree
   - override /logger: wandb

# Environment
env:
  data_path: ${user.data.root}/toy2.csv
  max_depth: 5
  continuous: False
  policy_format: mlp
  threshold_components: 3
  test_args:
    top_k_trees: 100
  buffer:
    replay_capacity: 100

# Proxy
proxy:
  reward_function: exponential
  beta: 32

# GFlowNet hyperparameters
gflownet:
  random_action_prob: 0.1
  replay_sampling: weighted
  optimizer:
    batch_size:
      forward: 90
      backward_dataset: 0
      backward_replay: 10
    lr: 0.001
    z_dim: 16
    lr_z_mult: 100
    n_train_steps: 10000
    lr_decay_period: 1000000

# MLP policy
policy:
  shared:
    type: mlp
    n_hid: 256
    n_layers: 3
  forward: null
  backward:
    shared_weights: False

# WandB
logger:
  lightweight: True
  project_name: "RF-GFN"
  tags:
    - gflownet
  test:
    period: 500
    n: 100
  checkpoints:
    period: 1000

# Hydra
hydra:
  run:
    dir: ${user.logdir.root}/rf-gfn/${now:%Y-%m-%d_%H-%M-%S}
