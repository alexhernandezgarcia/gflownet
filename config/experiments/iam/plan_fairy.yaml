# @package _global_
# Investment (single) environment trained with the Uniform proxy and the TB loss

defaults:
   - override /env: iam/plan
   - override /gflownet: trajectorybalance
   - override /proxy: iam/fairy
   - override /logger: wandb

# Buffer
buffer:
  test:
    type: pkl
    path: data/iam/test_set_v0.pkl
#    type: random
#    n: 100

# GFlowNet hyperparameters
gflownet:
  random_action_prob: 0.1
  optimizer:
    batch_size:
      forward: 10
    lr: 0.002
    z_dim: 8
    lr_z_mult: 100
    n_train_steps: 5000

# Policy
policy:
  forward:
    type: mlp
    n_hid: 1024
    n_layers: 2
  backward:
    shared_weights: True


# Proxy (eform)
proxy:
  reward_function: exponential
  # Parameters of the reward function
  reward_function_kwargs:
    beta: 0.1
    alpha: 1.0

# WandB
logger:
  do:
    online: False
  lightweight: True
  project_name: "iam-plan-fairy-test"
  run_name: "Plan Fairy TB"
  tags: 
    - gflownet
    - plan
    - uniform

# Evaluator
evaluator:
  first_it: True
  period: 25
  n: 100
  checkpoints_period: 1000

# Hydra
hydra:
  run:
    dir: ${user.logdir.root}/plan/uniform/${now:%Y-%m-%d_%H-%M-%S_%f}
